{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers import Embedding, multiply, BatchNormalization, Concatenate, Input\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import tarfile\n",
    "# 下載maps對應資料集, 網站裡面還有很多可以練習的資料集\n",
    "url = 'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/maps.tar.gz'\n",
    "dest = \"./maps.tar.gz\"\n",
    "urlretrieve(url, dest)\n",
    "# 解壓縮到maps資料夾\n",
    "f = tarfile.open(dest)\n",
    "f.extractall('./maps/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# 我使用PIL(要記得安裝Pillow函式庫)來方便後續的切割\n",
    "from PIL import Image\n",
    "# 原圖是 1024 * 512 的照片, 我們訓練的時候因為時間關係\n",
    "# 縮小一半為 512 * 256\n",
    "imglist = glob.glob('./maps/maps/train/*')\n",
    "# 拿第一張, 並且resize給你看\n",
    "oriimage = Image.open(imglist[0])\n",
    "oriimage.resize((512, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拿左邊的切法 crop(左邊座標, 上面座標, 右邊座標, 下面座標)\n",
    "# 就是(0, 0, 256, 256)\n",
    "left = oriimage.crop((0, 0, int(oriimage.size[0] / 2), oriimage.size[1]))\n",
    "left.resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拿右邊的切法 (256, 0, 512, 256)\n",
    "right = oriimage.crop((int(oriimage.size[0] / 2), 0, oriimage.size[0], oriimage.size[1]))\n",
    "right.resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先設定好shape方便使用\n",
    "img_shape = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 鑑賞家 Discriminator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 因為需要很多層, 所以製造一個方便的函數\n",
    "def d_layer(layer_input, filters, f_size=4):\n",
    "    # 卷積 -> Leaky Relu -> BN\n",
    "    # 直接使用 步長 = 2 的卷積 來代替 卷積 + 池化\n",
    "    d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    return d\n",
    "\n",
    "# Discriminator: 一次傳 地圖 + 街景\n",
    "# 地圖 + 真街景 -> 1(真)\n",
    "# 地圖 + 假街景 -> 0(假)\n",
    "img_A = Input(shape=img_shape)\n",
    "img_B = Input(shape=img_shape)\n",
    "# 合併在一起, axis=-1意味著最後一個軸\n",
    "# 所以每一個像素是 RGB(地圖) + RGB(街景) -> 6通道\n",
    "combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "# 四層卷積\n",
    "d1 = d_layer(combined_imgs, 64)\n",
    "d2 = d_layer(d1, 128)\n",
    "d3 = d_layer(d2, 256)\n",
    "d4 = d_layer(d3, 512)\n",
    "# 最後一層也是卷積, 特別的是filter只有1\n",
    "# 因為每一個像素就一個分數就好!\n",
    "validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "discriminator = Model([img_A, img_B], validity)\n",
    "# 使用adam的時候稍微調整一下學習速率和速度累積的幅度\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "discriminator.compile(loss='mse', optimizer=optimizer)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創作家 Generator\n",
    "\n",
    "# 正向卷積: 利用地圖產生靈感\n",
    "def conv2d(layer_input, filters, f_size=4):\n",
    "    # 卷積 -> LeakyRelu -> BN\n",
    "    # 一樣 步長 = 2 相等於 卷積 + 池化\n",
    "    d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    return d\n",
    "\n",
    "# 反向卷積: 靈感產生假街景\n",
    "def deconv2d(layer_input, skip_input, filters, f_size=4):\n",
    "    # 反池化 -> 卷積 -> LeakyRelu -> BN\n",
    "    u = UpSampling2D(size=2)(layer_input)\n",
    "    u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(u)\n",
    "    u = LeakyReLU(alpha=0.2)(u)\n",
    "    u = BatchNormalization()(u)\n",
    "    # 比較特別的是這裡, 我們說的UNet, 把對應層的特徵一起進來考慮, 產生的才不會跟原圖偏差太多\n",
    "    u = Concatenate()([u, skip_input])\n",
    "    return u\n",
    "\n",
    "# (256, 256, 3)的輸入: 傳入地圖\n",
    "d0 = Input(shape=img_shape)\n",
    "\n",
    "# 正向卷積, 長寬縮小, 特徵變多\n",
    "d1 = conv2d(d0, 64)\n",
    "d2 = conv2d(d1, 128)\n",
    "d3 = conv2d(d2, 256)\n",
    "d4 = conv2d(d3, 512)\n",
    "d5 = conv2d(d4, 512)\n",
    "d6 = conv2d(d5, 512)\n",
    "d7 = conv2d(d6, 512)\n",
    "d8 = conv2d(d7, 512)\n",
    "\n",
    "# 反向卷積, 長寬放大, 特徵變少\n",
    "u0 = deconv2d(d8, d7, 512)\n",
    "u1 = deconv2d(u0, d6, 512)\n",
    "u2 = deconv2d(u1, d5, 512)\n",
    "u3 = deconv2d(u2, d4, 512)\n",
    "u4 = deconv2d(u3, d3, 256)\n",
    "u5 = deconv2d(u4, d2, 128)\n",
    "u6 = deconv2d(u5, d1, 64)\n",
    "\n",
    "# 最後一次, filter數 = 3, 產生RGB圖片, activation使用tanh來產生 -1~1的圖片\n",
    "u7 = UpSampling2D(size=2)(u6)\n",
    "output_img = Conv2D(3, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "generator = Model(d0, output_img)\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 組合網路\n",
    "# 別忘了訓練Generator要把Discriminator接在後面, 才有所謂的GAN Loss\n",
    "# img_A: 原街景\n",
    "# img_B: 原地圖\n",
    "img_A = Input(shape=img_shape)\n",
    "img_B = Input(shape=img_shape)\n",
    "\n",
    "# fake_A: 假街景\n",
    "fake_A = generator(img_B)\n",
    "\n",
    "# 要把Discriminator固定住\n",
    "discriminator.trainable = False\n",
    "\n",
    "# [產生的假街景, 原地圖] 一起送進去鑑賞家判斷真假\n",
    "valid = discriminator([fake_A, img_B])\n",
    "\n",
    "# input:[原街景, 原地圖]  output:[真/假, 假地圖] for [GAN Loss, 傳統Loss]\n",
    "combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "\n",
    "# GAN Loss由於不是一個機率了, 所以我們改用 MSE\n",
    "# 傳統 Loss可以選擇 MAE 或 MSE\n",
    "# 由於 MSE 是平方, 不會一視同仁看待每一個像素, 而是差越多的懲罰愈大\n",
    "# 像是把優先把分數高的拉低, 而低的不懂, 所以會比 MAE 來的模糊, 因此我們通常選擇 MAE\n",
    "combined.compile(loss=['mse', 'mae'],\n",
    "                 loss_weights=[1, 100],\n",
    "                 optimizer=optimizer)\n",
    "combined.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備最後輸出的大小 (16, 16, 1)\n",
    "patch = int(256 / 2**4)\n",
    "disc_patch = (patch, patch, 1)\n",
    "disc_patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為圖片比較大, 我們一個batch少一點\n",
    "# 這裡我們準備 \n",
    "# 真 的答案: 4 個 (16, 16, 1) 填滿 1\n",
    "# 假 的答案: 4 個 (16, 16, 1) 填滿 0\n",
    "batch_size = 4\n",
    "valid = np.ones((batch_size,) + disc_patch)\n",
    "fake = np.zeros((batch_size,) + disc_patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count =  5000\n",
    "# 5000次一輪, 我大概訓練了10輪\n",
    "for train in range(0, train_count):\n",
    "    # 隨機4個index來拿圖片\n",
    "    rid = np.random.randint(0, len(imglist), batch_size)\n",
    "    # 上面教的! 把原本訓練資料的左右切出來\n",
    "    imgs_A = []\n",
    "    imgs_B = []\n",
    "    for i in rid:\n",
    "        \n",
    "        oriimage = Image.open(imglist[i])\n",
    "        left = oriimage.crop((0, 0, int(oriimage.size[0] / 2), oriimage.size[1]))\n",
    "        left = left.resize((256, 256))\n",
    "        left = np.array(left)\n",
    "\n",
    "        right = oriimage.crop((int(oriimage.size[0] / 2), 0, \n",
    "                               oriimage.size[0], oriimage.size[1]))\n",
    "        right = right.resize((256, 256))\n",
    "        right = np.array(right)\n",
    "\n",
    "        # 圖片處理到 -1~1之間\n",
    "        imgs_A.append((left - 127.5)/127.5)\n",
    "        imgs_B.append((right - 127.5)/127.5)\n",
    "\n",
    "    # 記得所有東西轉換成np array\n",
    "    imgs_A = np.array(imgs_A)\n",
    "    imgs_B = np.array(imgs_B)\n",
    "    # 產生假街景\n",
    "    fake_A = generator.predict(imgs_B)\n",
    "    # Step1. 訓練鑑賞家, [原地圖 真街景] -> 1 [原地圖 假街景] -> 0\n",
    "    d_loss_real = discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "    d_loss_fake = discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Step2. 訓練創作家\n",
    "    # GAN Loss:往鑑賞家心目中的1走 \n",
    "    # 傳統 Loss:跟原圖越接近越好\n",
    "    g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "    \n",
    "    if (train + 1) % 100 == 0:\n",
    "        dash = \"-\" * 15\n",
    "        print(dash, \"Train\", train + 1, dash)\n",
    "        print(\"Discriminator loss:\", d_loss)\n",
    "        print(\"Generator loss:\", g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對訓練資料看看我們的模型\n",
    "# 第一列: 原街景\n",
    "# 第二列: 原地圖\n",
    "# 第三列: 產生的街景\n",
    "import random\n",
    "from imageio import imread\n",
    "\n",
    "examples = 5\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i in range(examples):\n",
    "    idx = random.randint(0, len(imglist) - 1)\n",
    "\n",
    "    testimage = Image.open(imglist[idx])\n",
    "    testleft = testimage.crop((0, 0, int(testimage.size[0] / 2), testimage.size[1]))\n",
    "    testleft = testleft.resize((256, 256))\n",
    "    testleft = np.array(testleft)\n",
    "    testright = testimage.crop((int(testimage.size[0] / 2), 0, \n",
    "                                testimage.size[0], testimage.size[1]))\n",
    "    testright = testright.resize((256, 256))\n",
    "    testright = np.array(testright)\n",
    "\n",
    "    count = i + 1\n",
    "    plt.subplot(3, examples, count)\n",
    "    plt.title('View')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(testleft)\n",
    "    plt.subplot(3, examples, count + examples)\n",
    "    plt.title('Map')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(testright)\n",
    "\n",
    "    testright = (testright - 127.5)/127.5\n",
    "\n",
    "    trans = generator.predict(np.array([testright]))\n",
    "    trans = 0.5 * trans + 0.5\n",
    "    plt.subplot(3, examples, count + 2 * examples)\n",
    "    plt.title('Generated')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(trans[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 真的來預測從沒看過的資料\n",
    "# 第一列: 原街景\n",
    "# 第二列: 原地圖\n",
    "# 第三列: 產生的街景\n",
    "import random\n",
    "from imageio import imread\n",
    "\n",
    "val_imglist = glob.glob('./maps/maps/val/*')\n",
    "\n",
    "examples = 5\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i in range(examples):\n",
    "    idx = random.randint(0, len(val_imglist) - 1)\n",
    "\n",
    "    testimage = Image.open(val_imglist[idx])\n",
    "    testleft = testimage.crop((0, 0, int(testimage.size[0] / 2), testimage.size[1]))\n",
    "    testleft = testleft.resize((256, 256))\n",
    "    testleft = np.array(testleft)\n",
    "    testright = testimage.crop((int(testimage.size[0] / 2), 0, \n",
    "                                testimage.size[0], testimage.size[1]))\n",
    "    testright = testright.resize((256, 256))\n",
    "    testright = np.array(testright)\n",
    "\n",
    "    count = i + 1\n",
    "    plt.subplot(3, examples, count)\n",
    "    plt.title('View')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(testleft)\n",
    "    plt.subplot(3, examples, count + examples)\n",
    "    plt.title('Map')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(testright)\n",
    "\n",
    "    testright = (testright - 127.5)/127.5\n",
    "\n",
    "    trans = generator.predict(np.array([testright]))\n",
    "    trans = 0.5 * trans + 0.5\n",
    "    plt.subplot(3, examples, count + 2 * examples)\n",
    "    plt.title('Generated')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(trans[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
